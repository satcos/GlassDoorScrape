{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import ssl\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseURL = \"https://www.glassdoor.co.in/Reviews/Cognizant-Technology-Solutions-Reviews-E8014.htm\"\n",
    "outputFile = 'mydata.csv'\n",
    "companyName = 'CTS' # Just a identifier\n",
    "waitTime = 30 # Time in seconds\n",
    "columnNames = ['pageNo', 'company', 'datetime', 'summary', \n",
    "               'overallRating', 'WorkLifeBalance', 'CultureValues', \n",
    "               'CareerOpportunities', 'CompensationBenefits', 'SeniorManagement', \n",
    "               'pros', 'cons', 'location', 'jobtitle',\n",
    "              'recommend', 'outlook', 'CEO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subRatingTitle = {'Work/Life Balance':'WorkLifeBalance',\n",
    "                 'Culture & Values':'CultureValues',\n",
    "                 'Career Opportunities':'CareerOpportunities',\n",
    "                 'Compensation and Benefits':'CompensationBenefits',\n",
    "                 'Senior Management':'SeniorManagement'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://www.glassdoor.co.in/Reviews/Cognizant-Technology-Solutions-Reviews-E8014_P21.htm?sort.sortType=RD&sort.ascending=false\"\n",
    "# hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "# req = Request(url, headers=hdr)\n",
    "# gcontext = ssl.SSLContext()\n",
    "# page = urlopen(req, context=gcontext)\n",
    "# soup = BeautifulSoup(page, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews = soup.find_all('li', attrs={'class':'empReview'})\n",
    "# review = reviews[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommends = review.find_all('i', attrs={'class':'sqLed middle sm mr-xsm green'})\n",
    "# recommends[1].next_sibling.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_page(url):\n",
    "    hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "    req = Request(url, headers=hdr)\n",
    "    gcontext = ssl.SSLContext()\n",
    "    page = urlopen(req, context=gcontext)\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_content(review):\n",
    "    # Initilize the page with default content\n",
    "    content = {'company':companyName,\n",
    "              'location':'',\n",
    "              'jobtitle':'',\n",
    "              'recommend':'',\n",
    "              'outlook':'',\n",
    "              'CEO':''}\n",
    "    content['summary'] = review.a.text\n",
    "    content['datetime'] = review.time['datetime']\n",
    "    \n",
    "    overallRating = review.find_all('span', attrs = {'class':'value-title'})\n",
    "    content['overallRating'] = overallRating[0]['title']\n",
    "    \n",
    "    subRatings = review.find_all('div', attrs = {'class':'subRatings module stars__StarsStyles__subRatings'})\n",
    "    if len(subRatings) > 0:\n",
    "        subRatings = subRatings[0].find_all('div', attrs = {'class':'minor'})\n",
    "        for rate in subRatings:\n",
    "            content[subRatingTitle[rate.text]] = rate.next_sibling['title']\n",
    "    \n",
    "    proscons = review.find_all('p', attrs = {'class':'mt-0 mb-xsm v2__EIReviewDetailsV2__bodyColor v2__EIReviewDetailsV2__lineHeightLarge'})\n",
    "    content['pros'] = proscons[0].text\n",
    "    content['cons'] = proscons[1].text\n",
    "    \n",
    "    location = review.find_all('span', attrs={'class':'authorLocation'})\n",
    "    if len(location) > 0:\n",
    "        content['location'] = location[0].text\n",
    "        \n",
    "    jobtitle = review.find_all('span', attrs={'class':'authorJobTitle middle reviewer'})\n",
    "    if len(jobtitle) > 0:\n",
    "        content['jobtitle'] = jobtitle[0].text\n",
    "        \n",
    "        \n",
    "    recommends = review.find_all('i', attrs={'class':'sqLed middle sm mr-xsm green'})\n",
    "    if len(recommends) > 0:\n",
    "        for recommend in recommends:\n",
    "            recommendText = recommend.next_sibling.text\n",
    "            if 'CEO' in recommendText:\n",
    "                content['CEO'] = recommendText\n",
    "            elif 'Outlook' in recommendText:\n",
    "                content['outlook'] = recommendText\n",
    "            elif 'Recommend' in recommendText:\n",
    "                content['recommend'] = recommendText\n",
    "        \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function that is reusable. We need to scrape many pages of many companies\n",
    "def scraper(url, pageNo):\n",
    "    print(\"URL: \", url)\n",
    "    soup = download_page(url)\n",
    "    reviews = soup.find_all('li', attrs={'class':'empReview'})\n",
    "    if len(reviews) < 1:\n",
    "        print(soup)\n",
    "    result = []\n",
    "    for review in reviews:\n",
    "        content = process_content(review)\n",
    "        content['pageNo'] = pageNo\n",
    "        result.append(content)\n",
    "        \n",
    "    result = pd.DataFrame(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_URL(baseURL, pageNo):\n",
    "    return baseURL[:-4] + '_P' + str(pageNo) + \".htm?sort.sortType=RD&sort.ascending=false\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_stats(noRec, outputFile):\n",
    "    fullData = pd.read_csv(outputFile, encoding='utf-8')\n",
    "    print(\"{} new records, {} total records\".format(noRec, len(fullData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(baseURL, startPage, endPage, outputFile):\n",
    "    for pageNo in range(startPage, endPage + 1):\n",
    "        print('Processing Page No:', str(pageNo))\n",
    "        url = generate_URL(baseURL, pageNo)\n",
    "        result = scraper(url, pageNo)\n",
    "        if len(result) > 0:\n",
    "            result = pd.DataFrame(result, columns=columnNames)\n",
    "            with open(outputFile, 'a') as f:\n",
    "                result.to_csv(f, header=f.tell() == 0, index=False, encoding='utf-8')\n",
    "        update_stats(len(result), outputFile)\n",
    "        print('Idealing')\n",
    "        if pageNo != endPage: \n",
    "            time.sleep(waitTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Page No: 1\n",
      "URL:  https://www.glassdoor.co.in/Reviews/Cognizant-Technology-Solutions-Reviews-E8014_P1.htm?sort.sortType=RD&sort.ascending=false\n",
      "9 new records, 9 total records\n",
      "Idealing\n"
     ]
    }
   ],
   "source": [
    "# Adjust the start and end page number as required\n",
    "get_reviews(baseURL=baseURL, startPage=1, endPage=3, outputFile=outputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
